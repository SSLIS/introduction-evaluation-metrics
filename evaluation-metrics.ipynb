{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4z4ZdQtWwMRd"
   },
   "source": [
    "# Performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOvufB8ywM8_"
   },
   "source": [
    "With the help of this notebook, we will evaluate a search system's ability to provide us with relevant retrieved results through search queries. This is done through established metrics of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vi3APRIBRYfP"
   },
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz2uYrREjnWy"
   },
   "source": [
    "Let's start by documenting the documents from our queries that we deem relevant.\n",
    "\n",
    "Each document are represented by **1** (a relevant document) or **0** (an irrelevant document).\n",
    "\n",
    "The relevance assessment for each search are saved in a list that we call **query**; a container that we can use for computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71HTw4CtOlRf"
   },
   "source": [
    "### Query with relevance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w9ZUSrtnsooQ"
   },
   "outputs": [],
   "source": [
    "query = [0,1,0,0,1,0,1,0,0,1,0,0,1,0,0,0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iazTVbGPPCoJ"
   },
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVRHEdpiRV-x"
   },
   "source": [
    "Precision is the proportion of retrieved documents that are relevant.\n",
    "\n",
    "Answers the question *how precise is the query?*.\n",
    "\n",
    "Computed through relevant retrieved documents divided by all retrieved documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lE5LwA7_PKy3"
   },
   "outputs": [],
   "source": [
    "relevant_docs_in_query = query.count(1)\n",
    "print(\"Antal relevanta dokument:\", relevant_docs_in_query)\n",
    "\n",
    "retrieved_docs = len(query)\n",
    "print(\"Antal återvunna dokument:\", retrieved_docs)\n",
    "\n",
    "precision = relevant_docs_in_query/retrieved_docs\n",
    "print(\"Precision för sökningen =\", precision, \"≈\", round(precision * 100), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTne0c2CRCw2"
   },
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PAcqoxyhRCtJ"
   },
   "source": [
    "Recall is the proportion relevant documents that are retrieved.\n",
    "\n",
    "Answers the question *how many of the relevant documents has been retrieved from the query?*.\n",
    "\n",
    "Computed through relevant retrieved documents dievided by all relevant documents in the document set.\n",
    "\n",
    "Consider that there are 15 relevant documents in the document set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aQ6E2MdnRBwZ"
   },
   "outputs": [],
   "source": [
    "all_relevant_docs = 15\n",
    "\n",
    "recall = relevant_docs_in_query / all_relevant_docs\n",
    "\n",
    "print(\"Recall för sökningen är\", recall, \"≈\", round(recall * 100), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsqZYI-LvZmL"
   },
   "source": [
    "## Precision at n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQwlokyUj5tr"
   },
   "source": [
    "Precision at n (or p @ n) states the number of relevant documents at a given level (n).\n",
    "\n",
    "Computed at recall levels of 5, 10 and 20 since these levels usually are present in the number of documents that are presented of the first search query page.\n",
    "\n",
    "Below, we'll compute p @ n where n = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wjr7GBbIWOBd"
   },
   "outputs": [],
   "source": [
    "n = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjWdkK_jyuV8"
   },
   "outputs": [],
   "source": [
    "relevant_docs_in_query_at_n = sum(query[:n])\n",
    "print(\"Antal relevanta dokument =\", relevant_docs_in_query_at_n)\n",
    "\n",
    "p_at_n = relevant_docs_in_query_at_n / n\n",
    "print(\"Precision at n =\", p_at_n, \"≈\", round(p_at_n * 100), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMRr183RhwNb"
   },
   "source": [
    "## R-precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ELNorfaGmRN"
   },
   "source": [
    "Precision at the Rth position in the retrieved set, where R is the total number of relevant documents for a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y6k1PtLHhyl_"
   },
   "outputs": [],
   "source": [
    "print(\"Totalt antal relevanta dokument för sökfrågan (R):\", relevant_docs_in_query)\n",
    "\n",
    "r_position = sum(query[:relevant_docs_in_query])\n",
    "print(\"Antalet relevanta dokument vid R:\", r_position)\n",
    "\n",
    "r_precision = r_position / relevant_docs_in_query\n",
    "print(\"R-precision =\", r_precision, \"≈\", round(r_precision * 100), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQFi8QRlvqxy"
   },
   "source": [
    "## Average precision at document cut off value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOYdwIbikba1"
   },
   "source": [
    "Used to compute ranking efficiency for a query.\n",
    "\n",
    "Below, we'll compute AP/DCV where DCV = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iwCwrwsy_1Gp"
   },
   "outputs": [],
   "source": [
    "dcv = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w0-WmiGPuG4"
   },
   "source": [
    "We'll start by fetch a numbered list of the relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5S8eC7fpXMRY"
   },
   "outputs": [],
   "source": [
    "relevant_docs_in_query_at_dcv = sum(query[:dcv])\n",
    "index_zero_list = list(range(relevant_docs_in_query_at_dcv))\n",
    "\n",
    "doc_list = []\n",
    "\n",
    "for document_position in range(len(index_zero_list)):\n",
    "  doc_list.append(index_zero_list[document_position] + 1)\n",
    "\n",
    "print(\"Dokumentlista för sökningen:\", doc_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_Anxne0kun3"
   },
   "source": [
    "Then, we'll investigate the positions of each relevant retrieved document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8nTKDS9lP2C"
   },
   "outputs": [],
   "source": [
    "recall_levels = []\n",
    "\n",
    "for document, relevance in enumerate(query[:dcv]):\n",
    "  if relevance == 1: \n",
    "    recall_levels.append(document + 1)\n",
    "\n",
    "print(\"Recallnivåer för sökningen:\", recall_levels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkTiUit9k0gO"
   },
   "source": [
    "Next, we'll compute precision at each recall level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFMFHYdI1q_1"
   },
   "outputs": [],
   "source": [
    "precision_at_recall = []\n",
    "\n",
    "for each_precision, each_recall in zip(doc_list, recall_levels):\n",
    "  precision_at_recall.append(each_precision / each_recall)\n",
    "\n",
    "print(\"Precision vid varje recallnivå:\", precision_at_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1A61dyBlGft"
   },
   "source": [
    "We'll sum each precision value at each recall level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YN_SgGUvZFq2"
   },
   "outputs": [],
   "source": [
    "sum_precision = sum(precision_at_recall)\n",
    "\n",
    "print(\"Sammanlagd precision:\", sum_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MsLfPX5ljKL"
   },
   "source": [
    "We'll compute the total number of relevant documents at DCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ztx-nV7wVg2-"
   },
   "outputs": [],
   "source": [
    "relevant_docs_at_dcv = query[:dcv].count(1)\n",
    "\n",
    "print(\"Relevanta dokument vid document cut off value:\", relevant_docs_at_dcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7oplQXUylp-s"
   },
   "source": [
    "Finally, we'll compute AP/DCV for the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k0PPJq86ancP"
   },
   "outputs": [],
   "source": [
    "ap_dcv = sum_precision/dcv\n",
    "\n",
    "print(\"AP/DCV för sökningen =\", ap_dcv, \"≈\", round(ap_dcv * 100), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nleqBastj1oK"
   },
   "source": [
    "## F1 measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPuyYSs1F751"
   },
   "source": [
    "The F1 measure is a metric that combines recall and precision to compute the harmonic mean between precision and recall.\n",
    "\n",
    "2 / ((1/r) + (1/p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGuppOtgj3-B"
   },
   "outputs": [],
   "source": [
    "recall_f1 = 1/recall\n",
    "\n",
    "precision_f1 = 1/precision\n",
    "\n",
    "precision_recall_f1 = recall_f1 + precision_f1\n",
    "\n",
    "f1 = 2 / precision_recall_f1\n",
    "\n",
    "print(\"F1-måttet för sökningen =\", f1, \"≈\", round(f1 * 100), \"%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8u1toIaDf06y"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9TxmHeFflxv"
   },
   "outputs": [],
   "source": [
    "print(\"Precision ≈\", round(precision * 100), \"%.\")\n",
    "\n",
    "print(\"Recall ≈\", round(recall * 100), \"%.\")\n",
    "\n",
    "print(\"Precision @ n ≈\", round(p_at_n * 100), \"%.\")\n",
    "\n",
    "print(\"R-precision ≈\", round(r_precision * 100), \"%.\")\n",
    "\n",
    "print(\"AP/DCV ≈\", round(ap_dcv * 100), \"%\")\n",
    "\n",
    "print(\"F1 ≈\", round(f1 * 100), \"%.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
